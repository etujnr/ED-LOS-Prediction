{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Building - RawData_FeatureEng_FeatureSel_Class Balancing_github.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "k6_GveMIubU3",
        "CdB_NZGXuej6",
        "zQdywKvDuIX8",
        "coxITH1EuRQx",
        "E1w4rdxPuk4H",
        "bn0gN1klNnDq",
        "S9GMlV-xWOkO",
        "eedHWusGMbjm",
        "OmgCe_7H0phn",
        "MUdr7wIG1KDI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jNZHg8Dsp-V"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6_GveMIubU3"
      },
      "source": [
        "# Load Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MmPStKSt-UR"
      },
      "source": [
        "!pip install --upgrade pingouin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AivgSqkg6sI"
      },
      "source": [
        "import pingouin as pg\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from itertools import cycle\n",
        "from sklearn.metrics import (confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, classification_report)\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdB_NZGXuej6"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVjBZTBXBba8"
      },
      "source": [
        "df = pd.read_excel('###.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlWqAHcYB4Gt"
      },
      "source": [
        "da = df.drop(columns=['Unnamed: 0'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTXMMUT9QcxL"
      },
      "source": [
        "len(da.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQdywKvDuIX8"
      },
      "source": [
        "# Kolmogorov-Smirnov test for normality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOfXCthXT8H9"
      },
      "source": [
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from scipy.stats import Kstest\n",
        "\n",
        "data = da  #da['EDLengthofStayInHrs']\n",
        "\n",
        "# normality test\n",
        "stat, p = Kstest(data)\n",
        "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Sample looks Gaussian (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Sample does not look Gaussian (reject H0)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coxITH1EuRQx"
      },
      "source": [
        "# Defining the dependent and independent variables - based off Spearman Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW8FY4iyB5GR"
      },
      "source": [
        "X = da[['ESI_x',\t'Physician Available',\t'Nurse Available',\t'Bed Available',\t'Temp',\t'RR',\t'SpO2', 'HAS_AFIB',\t'HAS_CAD', 'HAS_CHRONIC_LUNG_DISEASE',\t\n",
        "        'HAS_CKD', 'HAS_CVD',\t'HAS_DIABETES',\t'HAS_PERIPH_VASC_DIS', 'HAS_OBESITY', 'PatientRace_Black']]\n",
        "\n",
        "y = da['EDLOS']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1w4rdxPuk4H"
      },
      "source": [
        "# Applying SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjxSWBRFDZ4q"
      },
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
        "\n",
        "s = SMOTE(random_state = 42) # SMOTE function for oversampling\n",
        "X_train_s, y_train_s = s.fit_sample(X_train, y_train.ravel())\n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_train_s.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_s.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_s==1)))\n",
        "print(\"After OverSampling, counts of label '0': {} \\n\".format(sum(y_train_s==0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn0gN1klNnDq"
      },
      "source": [
        "# Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKA_iKW1Nmth"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from numpy import mean, std\n",
        "scikit_default = LogisticRegression(random_state=0).fit(X_train_s, y_train_s)\n",
        "print(f\"intecept: {scikit_default.intercept_} coeficients: {scikit_default.coef_}\")\n",
        "print(f\"train accuracy: {scikit_default.score(X_train_s, y_train_s)}\")\n",
        "print(f\"test accuracy: {scikit_default.score(X_test, y_test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTqfArv1P7tu"
      },
      "source": [
        "# defining the dependent and independent variables\n",
        "# loading the testing dataset # df = pd.read_csv('logit_test1.csv', index_col = 0)\n",
        "Xtest = X_test\n",
        "ytest = y_test\n",
        "\n",
        "# performing predictions on the test datdaset\n",
        "yhat = scikit_default.predict(Xtest)\n",
        "prediction = list(map(round, yhat))\n",
        "  \n",
        "# comparing original and predicted values of y\n",
        "print('Acutal values', list(ytest.values))\n",
        "print('Predictions :', prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgTrj8a8vB24"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "rfc_cv_score = cross_val_score(scikit_default, X_train_s, y_train_s, cv=10, scoring='roc_auc')\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(ytest, prediction))\n",
        "print('\\n')\n",
        "\n",
        "# Classification report\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(ytest, prediction))\n",
        "print('\\n')\n",
        "\n",
        "print(\"=== All AUC Scores ===\")\n",
        "\n",
        "print(rfc_cv_score)\n",
        "print('\\n')\n",
        "\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n",
        "print(\"Std AUC Score - Random Forest: \", rfc_cv_score.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9GMlV-xWOkO"
      },
      "source": [
        "# Gradient Boosting Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGkhx2WXWSL9"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# define dataset\n",
        "X = da[['ESI_x',\t'Physician Available',\t'Nurse Available',\t'Bed Available',\t'Temp',\t'RR',\t'SpO2', 'HAS_AFIB',\t'HAS_CAD', 'HAS_CHRONIC_LUNG_DISEASE',\t\n",
        "        'HAS_CKD', 'HAS_CVD',\t'HAS_DIABETES',\t'HAS_PERIPH_VASC_DIS', 'HAS_OBESITY', 'PatientRace_Black']]\n",
        "y = da[['EDLOS']]\n",
        "\n",
        "# split into train/test sets\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8GjPkEXJMHb"
      },
      "source": [
        "clf = GradientBoostingClassifier(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
        "clf.fit(X_train_s, y_train_s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFVUOL-RJPz3"
      },
      "source": [
        "# optimal number of trees\n",
        "best_classifier = GradientBoostingClassifier(max_depth=4, n_estimators=2, learning_rate=1.0)\n",
        "best_classifier.fit(X_train_s, y_train_s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf5yNlaHJTl2"
      },
      "source": [
        "# performance evaluation\n",
        "y_pred = best_classifier.predict(Xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrXLJXBpo4yc"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "rfc_cv_score = cross_val_score(best_classifier, X_train_s, y_train_s, cv=10, scoring='roc_auc')\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(ytest, y_pred))\n",
        "print('\\n')\n",
        "\n",
        "# Classification report\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(ytest, y_pred))\n",
        "print('\\n')\n",
        "\n",
        "print(\"=== All AUC Scores ===\")\n",
        "\n",
        "print(rfc_cv_score)\n",
        "print('\\n')\n",
        "\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n",
        "print(\"Std AUC Score - Random Forest: \", rfc_cv_score.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eedHWusGMbjm"
      },
      "source": [
        "# Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFnKEyrpMd6F"
      },
      "source": [
        "feature_cols = ['ESI_x',\t'Physician Available',\t'Nurse Available',\t'Bed Available',\t'Temp',\t'RR',\t'SpO2', 'HAS_AFIB',\t'HAS_CAD', 'HAS_OBESITY',\n",
        "                'HAS_CHRONIC_LUNG_DISEASE',\t'HAS_CKD', 'HAS_CVD',\t'HAS_DIABETES',\t'HAS_PERIPH_VASC_DIS', 'PatientRace_Black']\n",
        "X = da[['ESI_x',\t'Physician Available',\t'Nurse Available',\t'Bed Available',\t'Temp',\t'RR',\t'SpO2', 'HAS_AFIB',\t'HAS_CAD', 'HAS_CHRONIC_LUNG_DISEASE',\t\n",
        "        'HAS_CKD', 'HAS_CVD',\t'HAS_DIABETES',\t'HAS_PERIPH_VASC_DIS', 'HAS_OBESITY', 'PatientRace_Black']]\n",
        "y = da[['EDLOS']]\n",
        "\n",
        "# Split dataset into training and test set\n",
        "X_train, X_test, y_train, ytest = train_test_split(X, y, test_size=0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9nM3lCYMnIU"
      },
      "source": [
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train_s, y_train_s)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhH0FNnQMn61"
      },
      "source": [
        "# Model Accuracy\n",
        "print(classification_report(ytest, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PACOPkGHMtwL"
      },
      "source": [
        "# Visualizing Tree\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(clf, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True,feature_names = feature_cols,class_names=['0','1'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png('EDLOS.png')\n",
        "Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyOZBIIuMvsK"
      },
      "source": [
        "# Optimizing Decision Tree\n",
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5) \n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clv = clf.fit(X_train_s, y_train_s)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clv.predict(X_test)\n",
        "\n",
        "# Model Accuracy\n",
        "print(classification_report(ytest, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR5Re4NqNA0g"
      },
      "source": [
        "# Visualizing optimal tree\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "dot_data = StringIO()\n",
        "export_graphviz(clf, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True, feature_names = feature_cols,class_names=['0','1'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png('EDLOS.png')\n",
        "Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4Dtvkhimde1"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "rfc_cv_score = cross_val_score(clv, X_train_s, y_train_s, cv=10, scoring='roc_auc')\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('\\n')\n",
        "\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('\\n')\n",
        "\n",
        "print(\"=== All AUC Scores ===\")\n",
        "\n",
        "print(rfc_cv_score)\n",
        "print('\\n')\n",
        "\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n",
        "print(\"Std AUC Score - Random Forest: \", rfc_cv_score.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmgCe_7H0phn"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utQ2i6hI0o6q"
      },
      "source": [
        "# Import train_test_split function\n",
        "X = da[['ESI_x',\t'Physician Available',\t'Nurse Available',\t'Bed Available',\t'Temp',\t'RR',\t'SpO2', 'HAS_AFIB',\t'HAS_CAD', 'HAS_CHRONIC_LUNG_DISEASE',\t\n",
        "        'HAS_CKD', 'HAS_CVD',\t'HAS_DIABETES',\t'HAS_PERIPH_VASC_DIS', 'HAS_OBESITY', 'PatientRace_Black']]\n",
        "y = da[['EDLOS']]\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX5UNNPw7Ovy"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#Create a Gaussian Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clf.fit(X_train_s, y_train_s)\n",
        "\n",
        "#Predict\n",
        "ypredt=clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdS3f2JDYLS1"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "rfc_cv_score = cross_val_score(clf, X_train_s, y_train_s, cv=10, scoring='roc_auc')\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, ypredt))\n",
        "print('\\n')\n",
        "\n",
        "# Classification report\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, ypredt))\n",
        "print('\\n')\n",
        "\n",
        "print(\"=== All AUC Scores ===\")\n",
        "\n",
        "print(rfc_cv_score)\n",
        "print('\\n')\n",
        "\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n",
        "print(\"Std AUC Score - Random Forest: \", rfc_cv_score.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUdr7wIG1KDI"
      },
      "source": [
        "# Training Multiple Classifiers and Recording the Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQNrabhG1JxW"
      },
      "source": [
        "# Import the classifiers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import roc_curve, roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy57URfS1eo5"
      },
      "source": [
        "# Instantiate the classfiers and make a list\n",
        "classifiers = [LogisticRegression(random_state = 42), \n",
        "               GradientBoostingClassifier(max_depth=4, n_estimators=2, learning_rate=1.0),\n",
        "               DecisionTreeClassifier(random_state = 42, criterion=\"entropy\", max_depth=5),\n",
        "               RandomForestClassifier(random_state = 42, n_estimators=100, criterion='entropy')]\n",
        "\n",
        "# Define a result table as a DataFrame\n",
        "result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CM5U40Z1xH_"
      },
      "source": [
        "# Train the models and record the results\n",
        "for cls in classifiers:\n",
        "    model = cls.fit(X_train_s, y_train_s)\n",
        "    yproba = model.predict_proba(X_test)[::,1]\n",
        "    \n",
        "    fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
        "    auc = roc_auc_score(y_test, yproba)\n",
        "    \n",
        "    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n",
        "                                        'fpr':fpr, \n",
        "                                        'tpr':tpr, \n",
        "                                        'auc':auc,}, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMARVwe32JbK"
      },
      "source": [
        "# Set name of the classifiers as index labels\n",
        "result_table.set_index('classifiers', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDwJNP3y2KSH"
      },
      "source": [
        "fig = plt.figure(figsize=(8,6))\n",
        "\n",
        "for i in result_table.index:\n",
        "    plt.plot(result_table.loc[i]['fpr'], \n",
        "             result_table.loc[i]['tpr'], \n",
        "             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
        "    \n",
        "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
        "\n",
        "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.title('ROC Curve Analysis for Different Models - SMOTE applied data', fontweight='bold', fontsize=15)\n",
        "plt.legend(prop={'size':13}, loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8yaWI4IhCeH"
      },
      "source": [
        "# Operational Point for AUC\n",
        "from numpy import argmax\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "# Calculate roc curves\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, yproba)\n",
        "# Convert to f score\n",
        "fscore = (2 * precision * recall)/(precision + recall)\n",
        "# Locate the index of the largeest f score\n",
        "ix = argmax(fscore)\n",
        "print('Best Threshold=%f, F-score=%.3f' % (thresholds[ix], fscore[ix]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}